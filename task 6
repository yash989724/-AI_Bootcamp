
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import classification_report
import numpy as np

# 1. Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize pixel values to range [0, 1]
x_train = x_train / 255.0
x_test = x_test / 255.0

# One-hot encode the labels for training
y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)

# 2. Build the Neural Network model
model = Sequential([
    Flatten(input_shape=(28, 28)),          # a. Input Layer
    Dense(400, activation='relu'),          # b. Hidden Layer 1
    Dense(128, activation='relu'),          # c. Hidden Layer 2
    Dense(10, activation='softmax')         # d. Output Layer
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train_cat, epochs=10, batch_size=32, validation_split=0.1)

# 3. Evaluate using classification report
# Predict class probabilities for test set
y_pred_probs = model.predict(x_test)

# Convert predicted probabilities to class labels
y_pred = np.argmax(y_pred_probs, axis=1)

# Print classification report
print("Classification Report:\n")
print(classification_report(y_test, y_pred))
